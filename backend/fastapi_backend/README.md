# ğŸš€ FastAPI Backend - Examecho AI Service

A FastAPI-based backend service for the Examecho exam portal with Speech-to-Text (STT), Text-to-Speech (TTS), and answer evaluation capabilities.

---

## ğŸ“ Project Structure

```
fastapi_backend/
â”œâ”€â”€ app/                          # Main application
â”‚   â”œâ”€â”€ main.py                     # FastAPI app entry point
â”‚   â”œâ”€â”€ config.py                   # Configuration
â”‚   â”œâ”€â”€ routers/                    # API routes
â”‚   â”‚   â”œâ”€â”€ stt.py                      # Speech-to-Text routes
â”‚   â”‚   â”œâ”€â”€ tts.py                      # Text-to-Speech routes
â”‚   â”‚   â””â”€â”€ evaluation.py               # Answer evaluation routes
â”‚   â”œâ”€â”€ schemas/                    # Pydantic models
â”‚   â”œâ”€â”€ services/                   # Business logic
â”‚   â”‚   â”œâ”€â”€ stt_service.py
â”‚   â”‚   â”œâ”€â”€ tts_service.py
â”‚   â”‚   â””â”€â”€ evaluation_service.py
â”‚   â””â”€â”€ core/models.py              # Shared model instances
â”œâ”€â”€ ai_ml/                        # AI/ML models
â”‚   â”œâ”€â”€ Speech2Text.py              # Whisper STT
â”‚   â”œâ”€â”€ Text2Speech.py              # gTTS TTS
â”‚   â”œâ”€â”€ Evaluation.py               # LLM evaluation
â”‚   â”œâ”€â”€ AudioPreprocessor.py        # Audio utilities
â”‚   â””â”€â”€ AIExceptions.py             # Custom exceptions
â”œâ”€â”€ generated_audio/              # Output audio files
â”œâ”€â”€ Dockerfile                    # Docker setup
â”œâ”€â”€ requirements.txt              # Dependencies
â””â”€â”€ README.md
```

---

## ğŸš€ Quick Start

### ğŸ“¦ Installation

```bash
# Clone repository
git clone https://github.com/aryanshah2109/STT-TTS-exam-portal.git
cd backend/fastapi_backend

# Setup virtual environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### â–¶ï¸ Running

#### Local Development

```bash
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

#### Docker

```bash
docker build -t examecho-backend .
docker run -p 8000:8000 examecho-backend
```

**Access API docs:** `http://localhost:8000/docs`

---

## ğŸ”Œ API Endpoints

### ğŸ’š Health Check

```
GET /health
```

- **Response:** `{"status": "ok"}`

### ğŸ¤ Speech-to-Text (STT)

```
POST /stt/transcribe
```

- **File:** Audio file (WAV, MP3, MP4, WebM)
- **Query Parameters:**
  - `lang` - Language code (default: `en`)
  - `model` - Model name (default: `whisper`)
- **Response:** 
  ```json
  {
    "text": "Transcribed text",
    "language": "en",
    "model": "whisper"
  }
  ```

### ğŸ”Š Text-to-Speech (TTS)

```
POST /tts/synthesize
```

- **Request Body:**
  ```json
  {
    "text": "Hello world",
    "language": "en",
    "slow": false
  }
  ```
- **Response:**
  ```json
  {
    "text": "Hello world",
    "audio_path": "/generated_audio/audio_123.mp3",
    "language": "en"
  }
  ```

### âœ… Answer Evaluation

```
POST /evaluate/answer
```

- **Request Body:**
  ```json
  {
    "question_id": "q134",
    "question_text": "What is the capital of France?",
    "student_answer": "Paris",
    "marks": "20"
  }
  ```
- **Response:**
  ```json
  {
    "question_id": "q134",
    "score": 15,
    "strengths": [
        "The student answered the question very well",
        "The answer was according to the rubrics of the questions"
    ],
    "weakness": [
        "Answer can be more detailed",       
    ],
    "justification": "Correct answer!",
    "suggested_improvement": "Try to add more depth to the answer"
  }
  ```

---

## âš™ï¸ Configuration

Create `.env` file in the root directory:

```env
HF_EVAL_MODEL_NAME=microsoft/Phi-3.5-mini-instruct
STT_DEFAULT_MODEL=whisper
HF_TOKEN=your_token  # Optional
```

---

## ğŸ—ï¸ Architecture Overview

**Layered Design:**

- **ğŸŒ Routers:** Handle HTTP requests and input validation
- **ğŸ“‹ Schemas:** Pydantic models for request/response validation
- **âš™ï¸ Services:** Business logic layer
- **ğŸ¤– AI/ML:** Model inference and audio processing
- **ğŸ’¾ Core Models:** Global model instances (Whisper, Phi-3.5)

**Model Lifecycle:** Models are preloaded on startup to reduce latency on first requests.

---

## âœ¨ Key Features

- âœ… Multi-language speech recognition (Whisper)
- âœ… Text-to-speech synthesis (gTTS)
- âœ… Intelligent answer evaluation (Phi-3.5 LLM)
- âœ… Audio preprocessing (noise reduction, VAD)
- âœ… Async request handling
- âœ… Docker containerization
- âœ… Swagger API documentation

---

## ğŸ“š Dependencies

### Core Stack
- **Web Framework:** FastAPI, Uvicorn, Pydantic
- **AI/ML:** Whisper, Transformers, LangChain
- **Audio Processing:** Librosa, SoundFile, pydub, noisereduce
- **TTS:** gTTS
- **Utilities:** python-dotenv, numpy, scipy

See `requirements.txt` for complete list with versions.

---

## ğŸ› ï¸ Development

### Code Structure

- âœ“ Follow PEP 8 style guide
- âœ“ Use type hints for functions
- âœ“ Add docstrings for modules
- âœ“ Use async/await for I/O operations

### Adding New Endpoints

**Steps:**

1. Create schema in `app/schemas/`
2. Create service in `app/services/`
3. Create router in `app/routers/`
4. Include router in `app/main.py`

**Example:**

```python
# app/routers/new_feature.py
from fastapi import APIRouter
from app.services.new_service import process_request

router = APIRouter(prefix="/new", tags=["new"])

@router.post("/endpoint")
async def new_endpoint(payload: RequestModel):
    result = process_request(payload)
    return ResponseModel(**result)
```

---

## ğŸ”§ Troubleshooting

|--------------- Issue --------------|-----------------Solution--------------------|
|------------------------------------|---------------------------------------------|
| ğŸ“¥ Model download errors          | Set `HF_TOKEN` for authenticated access      |
| ğŸµ Audio format not supported     | Convert to WAV/MP3; check MIME types         |
| ğŸ’¾ Out of memory                  | Use smaller models or increase RAM           |
| âš ï¸ Port 8000 in use               | Use different port: `docker run -p 9000:8000`|

---

## ğŸŒŸ Production Deployment

Run with multiple workers for better performance:

```bash
uvicorn app.main:app --host 0.0.0.0 --port 8000 --workers 4
```

---

## ğŸ“– Resources

- **ğŸ“¦ Repository:** https://github.com/aryanshah2109/STT-TTS-exam-portal
- **ğŸ“„ API Docs:** http://localhost:8000/docs
- **ğŸ”— FastAPI Docs:** https://fastapi.tiangolo.com/

---

**Last Updated:** December 2025
